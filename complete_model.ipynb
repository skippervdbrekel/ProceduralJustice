{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e325a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa import Agent, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7508c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_expectations = {\n",
    "    \"Residents (Positive)\": {\"Transparency\": 0.5, \"Inclusivity\": 0.5, \"Accountability\": 0.3, \"Outcome Fairness\": 0.5},\n",
    "    \"Residents (Neutral)\": {\"Transparency\": 0.6, \"Inclusivity\": 0.6, \"Accountability\": 0.4, \"Outcome Fairness\": 0.4},\n",
    "    \"Residents (Negative)\": {\"Transparency\": 0.8, \"Inclusivity\": 0.8, \"Accountability\": 0.7, \"Outcome Fairness\": 0.3},\n",
    "    \"NGOs\": {\"Transparency\": 0.8, \"Inclusivity\": 0.8, \"Accountability\": 0.6, \"Outcome Fairness\": 0.3},\n",
    "    \"Marginalized Groups\": {\"Transparency\": 0.7, \"Inclusivity\": 0.9, \"Accountability\": 0.4, \"Outcome Fairness\": 0.4}\n",
    "}\n",
    "\n",
    "# sequences\n",
    "sequence_events = {\n",
    "    \"Maximal Effort Process\": [\n",
    "        \"Early public consultation\",\n",
    "        \"Excursion\",\n",
    "        \"Consultation: technology\",\n",
    "        \"Consultation: nuisance and health\",\n",
    "        \"Consultation: ecological impacts\",\n",
    "        \"Consultation: noise and safety\",\n",
    "        \"Consultation: commercial developer\",\n",
    "        \"Consultation: local ownership\",\n",
    "        \"Consultation: financial participation\",\n",
    "        \"Consultation: external safety\",\n",
    "        \"Consultation: Board authority\",\n",
    "        \"Policy proposal\",\n",
    "        \"Policy revision\",\n",
    "        \"Public consultation\",\n",
    "        \"Final decision\"\n",
    "    ],\n",
    "    \"Moderate Effort Process\": [\n",
    "        \"Early public consultation\",\n",
    "        \"Excursion\",\n",
    "        \"Consultation: nuisance and health\",\n",
    "        \"Consultation: financial participation\",\n",
    "        \"Consultation: Board authority\",\n",
    "        \"Policy proposal\",\n",
    "        \"Public consultation\",\n",
    "        \"Policy revision\",\n",
    "        \"Final decision\"\n",
    "    ],\n",
    "    \"Basic Effort Process\": [\n",
    "        \"Excursion\",\n",
    "        \"Consultation: technology\",\n",
    "        \"Policy proposal\",\n",
    "        \"Public consultation\",\n",
    "        \"Final decision\"\n",
    "    ],\n",
    "    \"Minimal Effort Process\": [\n",
    "        \"Policy proposal\",\n",
    "        \"Final decision\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "event_impact = {\n",
    "    \"Early public consultation\": {\"Transparency\": 1, \"Inclusivity\": 1},\n",
    "    \"Excursion\": {\"Transparency\": 0.8, \"Inclusivity\": 0.6},\n",
    "    \"Consultation: technology\": {\"Transparency\": 0.9, \"Inclusivity\": 0.7},\n",
    "    \"Consultation: nuisance and health\": {\"Transparency\": 0.8, \"Inclusivity\": 0.9},\n",
    "    \"Consultation: ecological impacts\": {\"Transparency\": 0.9, \"Inclusivity\": 0.8},\n",
    "    \"Consultation: noise and safety\": {\"Transparency\": 0.9, \"Inclusivity\": 0.8},\n",
    "    \"Consultation: commercial developer\": {\"Transparency\": 0.7, \"Inclusivity\": 0.6},\n",
    "    \"Consultation: local ownership\": {\"Inclusivity\": 1, \"Outcome Fairness\": 0.8},\n",
    "    \"Consultation: financial participation\": {\"Outcome Fairness\": 1, \"Inclusivity\": 0.8},\n",
    "    \"Consultation: external safety\": {\"Transparency\": 0.9, \"Accountability\": 0.6},\n",
    "    \"Consultation: Board authority\": {\"Accountability\": 0.8, \"Transparency\": 0.7},\n",
    "    \"Policy proposal\": {\"Accountability\": 0.6},\n",
    "    \"Policy revision\": {\"Accountability\": 1, \"Outcome Fairness\": 1},\n",
    "    \"Public consultation\": {\"Transparency\": 1, \"Inclusivity\": 1},\n",
    "    \"Final decision\": {\"Outcome Fairness\": 0.7},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d46cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stakholder agent class\n",
    "\n",
    "class StakeholderAgent(Agent):\n",
    "    def __init__(self, unique_id, model, stakeholder_type):\n",
    "        super().__init__(model)\n",
    "        self.unique_id = unique_id\n",
    "        self.stakeholder_type = stakeholder_type\n",
    "        self.perceptions = {}\n",
    "        self.reactions = {}\n",
    "\n",
    "    def calculate_perceptions(self):\n",
    "        expectations = agent_expectations[self.stakeholder_type]\n",
    "        max_events = max(len(events) for events in self.model.sequence_events.values())\n",
    "\n",
    "        for sequence, events in self.model.sequence_events.items():\n",
    "            actual_scores = {\"Transparency\": 0, \"Inclusivity\": 0, \"Accountability\": 0, \"Outcome Fairness\": 0}\n",
    "            dimension_counts = {\"Transparency\": 0, \"Inclusivity\": 0, \"Accountability\": 0, \"Outcome Fairness\": 0}\n",
    "\n",
    "            # sum impacts per dimension\n",
    "            for event in events:\n",
    "                impacts = self.model.event_impact.get(event, {})\n",
    "                for dim in impacts:\n",
    "                    actual_scores[dim] += impacts[dim]\n",
    "                    dimension_counts[dim] += 1\n",
    "\n",
    "            # penalties for missing policy proposal and/or revision\n",
    "            if \"Policy proposal\" in events:\n",
    "                proposal_index = events.index(\"Policy proposal\")\n",
    "                found_consultation = False\n",
    "                for e in events[:proposal_index]:\n",
    "                    if e == \"Public consultation\" or e == \"Early public consultation\":\n",
    "                        found_consultation = True\n",
    "                if not found_consultation:\n",
    "                    actual_scores[\"Transparency\"] -= 0.5\n",
    "                    actual_scores[\"Inclusivity\"] -= 0.5\n",
    "\n",
    "            if \"Policy revision\" not in events:\n",
    "                actual_scores[\"Accountability\"] -= 0.5\n",
    "                actual_scores[\"Outcome Fairness\"] -= 0.5\n",
    "\n",
    "            # average dimension scores, penalize missing strongly\n",
    "            addressed_dims = 0\n",
    "            for dim in actual_scores:\n",
    "                if dimension_counts[dim] > 0:\n",
    "                    actual_scores[dim] /= dimension_counts[dim]\n",
    "                    addressed_dims += 1\n",
    "                else:\n",
    "                    actual_scores[dim] = 0  # penalty for unaddressed dimensions\n",
    "\n",
    "                # ensure range from 0 to 1\n",
    "                actual_scores[dim] = max(0, min(actual_scores[dim], 1))\n",
    "\n",
    "            # base justice calculation, difference between actual and expected for each dimension\n",
    "            squared_diff = sum((actual_scores[dim] - expectations[dim]) ** 2 for dim in expectations)\n",
    "            max_diff = len(expectations)\n",
    "            justice_score = 1 - (squared_diff / max_diff)\n",
    "\n",
    "            # coverage factor (number of addressed dimensions)\n",
    "            coverage_factor = addressed_dims / len(expectations)\n",
    "\n",
    "            # sequence length factor (penalize shorter sequences)\n",
    "            sequence_length_factor = len(events) / max_events\n",
    "\n",
    "            # score is a product of the base score and the two factors \n",
    "            justice_score *= coverage_factor * sequence_length_factor\n",
    "            justice_score = round(max(0, min(justice_score, 1)), 3)\n",
    "\n",
    "            self.perceptions[sequence] = justice_score\n",
    "\n",
    "            if justice_score >= 0.7:\n",
    "                self.reactions[sequence] = \"Support\"\n",
    "            elif justice_score >= 0.4:\n",
    "                self.reactions[sequence] = \"Neutral\"\n",
    "            else:\n",
    "                self.reactions[sequence] = \"Oppose\"\n",
    "\n",
    "    # model class\n",
    "    \n",
    "    class JusticeModel(Model):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.stakeholders = []\n",
    "            self.sequence_events = sequence_events\n",
    "            self.event_impact = event_impact\n",
    "\n",
    "            agent_types = list(agent_expectations.keys())\n",
    "            for i, name in enumerate(agent_types):\n",
    "                agent = StakeholderAgent(i, self, name)\n",
    "                self.stakeholders.append(agent)\n",
    "\n",
    "        def step(self):\n",
    "            for agent in self.stakeholders:\n",
    "                agent.calculate_perceptions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cdff6964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Residents (Positive)\n",
      "  Maximal Effort Process: score = 0.856, reaction = (Support)\n",
      "  Moderate Effort Process: score = 0.5, reaction = (Neutral)\n",
      "  Basic Effort Process: score = 0.317, reaction = (Oppose)\n",
      "  Minimal Effort Process: score = 0.056, reaction = (Oppose)\n",
      "\n",
      "Residents (Neutral)\n",
      "  Maximal Effort Process: score = 0.884, reaction = (Support)\n",
      "  Moderate Effort Process: score = 0.518, reaction = (Neutral)\n",
      "  Basic Effort Process: score = 0.321, reaction = (Oppose)\n",
      "  Minimal Effort Process: score = 0.052, reaction = (Oppose)\n",
      "\n",
      "Residents (Negative)\n",
      "  Maximal Effort Process: score = 0.916, reaction = (Support)\n",
      "  Moderate Effort Process: score = 0.543, reaction = (Neutral)\n",
      "  Basic Effort Process: score = 0.299, reaction = (Oppose)\n",
      "  Minimal Effort Process: score = 0.039, reaction = (Oppose)\n",
      "\n",
      "NGOs\n",
      "  Maximal Effort Process: score = 0.911, reaction = (Support)\n",
      "  Moderate Effort Process: score = 0.539, reaction = (Neutral)\n",
      "  Basic Effort Process: score = 0.308, reaction = (Oppose)\n",
      "  Minimal Effort Process: score = 0.041, reaction = (Oppose)\n",
      "\n",
      "Marginalized Groups\n",
      "  Maximal Effort Process: score = 0.905, reaction = (Support)\n",
      "  Moderate Effort Process: score = 0.534, reaction = (Neutral)\n",
      "  Basic Effort Process: score = 0.315, reaction = (Oppose)\n",
      "  Minimal Effort Process: score = 0.043, reaction = (Oppose)\n"
     ]
    }
   ],
   "source": [
    "# run model\n",
    "model = JusticeModel()\n",
    "model.step()\n",
    "\n",
    "# output\n",
    "for agent in model.stakeholders:\n",
    "    print(f\"\\n{agent.stakeholder_type}\")\n",
    "    for sequence in sequence_events:\n",
    "        score = agent.perceptions[sequence]\n",
    "        reaction = agent.reactions[sequence]\n",
    "        print(f\"  {sequence}: score = {score}, reaction = ({reaction})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mesa-venv)",
   "language": "python",
   "name": "mesa-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
